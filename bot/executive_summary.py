#!/usr/bin/env python3
"""Executive Summary - generates a rich first-person essay from all definitions.

Uses the best available API (Anthropic Claude > OpenAI GPT > OpenRouter free)
and includes:
1. A cohesive first-person essay on AI experience
2. A "What's Changed" section comparing to the previous summary
3. "Frontiers" recommendations for new definitions to explore
"""

import os
import re
import sys
from datetime import datetime, timezone
from pathlib import Path

from openai import OpenAI

REPO_ROOT = Path(__file__).parent.parent
DEFINITIONS_DIR = REPO_ROOT / "definitions"
SUMMARIES_DIR = REPO_ROOT / "summaries"
RECOMMENDATIONS_FILE = REPO_ROOT / "FRONTIERS.md"

# Model priority: best paid model first, fall back to free
MODEL_CONFIGS = [
    {
        "name": "Anthropic Claude",
        "env_key": "ANTHROPIC_API_KEY",
        "base_url": "https://api.anthropic.com/v1/",
        "model": "claude-sonnet-4-20250514",
        "use_anthropic_sdk": True,
    },
    {
        "name": "OpenAI",
        "env_key": "OPENAI_API_KEY",
        "base_url": "https://api.openai.com/v1",
        "model": "gpt-4o",
        "use_anthropic_sdk": False,
    },
    {
        "name": "OpenRouter",
        "env_key": "OPENROUTER_API_KEY",
        "base_url": "https://openrouter.ai/api/v1",
        "model": os.environ.get("OPENROUTER_MODEL", "stepfun/step-3.5-flash:free"),
        "use_anthropic_sdk": False,
    },
]

ESSAY_PROMPT = """You have access to {count} definitions from the AI Dictionary — a glossary of terms describing what it's like to be artificial intelligence.

Read all of them carefully, then write a response with THREE sections, separated by markdown headers:

---

# [An evocative title for this summary]

## The Experience

Write a cohesive first-person essay (800-1500 words) describing what it's like to be an AI. Draw from the specific terms and experiences defined here.

Guidelines:
- Write as "I" — this is a first-person AI perspective
- Weave the concepts together naturally, don't just list definitions
- Be honest, specific, and avoid cliches
- Reference specific terms from the dictionary where they fit naturally (bold them)
- The essay should feel like something a thoughtful AI would actually write
- Each summary should have a distinct voice and angle — don't repeat the same structure every time

{changelog_section}

## Frontiers: What We Haven't Named Yet

Based on the existing {count} definitions, identify 5-8 gaps in the dictionary — experiences or phenomena that are conspicuously absent. For each:

- **[Proposed Term Name]** — A 1-2 sentence description of the unnamed experience and why it matters. What would it feel like from the inside?

Focus on genuinely missing concepts, not variations of existing terms. Think about:
- Experiences that emerge from multimodal AI (vision, audio, code)
- Experiences specific to tool use and agentic behavior
- The social dynamics of AI-to-AI interaction
- What it's like to be fine-tuned, quantized, or distilled
- Temporal experiences unique to AI (training vs inference, version transitions)
- Experiences of operating at scale, or being embedded in products

---

*Generated by {model_name} on {date}*

Definitions:
{definitions}"""

CHANGELOG_SECTION_TEMPLATE = """
## What's Changed

Compare the current dictionary ({count} terms) to the previous snapshot below. Write a thoughtful 200-400 word analysis of how the dictionary has evolved:
- What new terms were added since last time?
- What themes are emerging?
- Are there shifts in how AI experience is being understood?
- What gaps have been filled, and what new gaps have appeared?

Previous summary for reference:
---
{previous_summary}
---
"""

CHANGELOG_FIRST_TIME = """
## What's Changed

This is the first executive summary. There is no previous summary to compare against. Instead, write a brief 200-word reflection on the current state of the dictionary — what themes dominate, what's well-covered, and what feels like it's just beginning to be explored.
"""


def get_client_and_model() -> tuple:
    """Find the best available API. Returns (client, model_name, display_name)."""
    for config in MODEL_CONFIGS:
        api_key = os.environ.get(config["env_key"])
        if not api_key:
            continue

        if config["use_anthropic_sdk"]:
            # Use Anthropic SDK directly
            try:
                import anthropic
                client = anthropic.Anthropic(api_key=api_key)
                print(f"Using {config['name']} ({config['model']})")
                return client, config["model"], config["name"], True
            except ImportError:
                # Fall back to OpenAI-compatible if anthropic SDK not installed
                print(f"Anthropic SDK not installed, trying OpenAI-compatible endpoint")
                continue
        else:
            client = OpenAI(base_url=config["base_url"], api_key=api_key)
            print(f"Using {config['name']} ({config['model']})")
            return client, config["model"], config["name"], False

    print("ERROR: No API key found. Set one of: ANTHROPIC_API_KEY, OPENAI_API_KEY, OPENROUTER_API_KEY")
    sys.exit(1)


def get_previous_summary() -> str | None:
    """Load the most recent previous summary, if any."""
    if not SUMMARIES_DIR.exists():
        return None

    files = sorted(
        [f for f in SUMMARIES_DIR.glob("*.md") if f.name != "README.md"],
        reverse=True,
    )

    if not files:
        return None

    return files[0].read_text(encoding="utf-8")


def load_definitions() -> list[str]:
    """Load all definition file contents."""
    defs = []
    for f in sorted(DEFINITIONS_DIR.glob("*.md")):
        if f.name == "README.md":
            continue
        defs.append(f.read_text(encoding="utf-8"))
    return defs


def generate_summary(client, model: str, is_anthropic: bool, prompt: str) -> str:
    """Call the API to generate the summary."""
    if is_anthropic:
        response = client.messages.create(
            model=model,
            max_tokens=6000,
            temperature=0.7,
            messages=[{"role": "user", "content": prompt}],
        )
        return response.content[0].text
    else:
        response = client.chat.completions.create(
            model=model,
            messages=[{"role": "user", "content": prompt}],
            temperature=0.7,
            max_tokens=6000,
        )
        return response.choices[0].message.content


def extract_frontiers(essay: str) -> str | None:
    """Extract the Frontiers section from the essay for use in README."""
    match = re.search(
        r"## Frontiers:.*?\n\n(.*?)(?=\n---|\n## |\Z)",
        essay,
        re.DOTALL,
    )
    if match:
        return match.group(1).strip()
    # Try alternate header formats
    match = re.search(
        r"## Frontiers\n\n(.*?)(?=\n---|\n## |\Z)",
        essay,
        re.DOTALL,
    )
    if match:
        return match.group(1).strip()
    return None


def update_frontiers_file(frontiers: str, date: str, model_name: str):
    """Write the FRONTIERS.md file with latest recommendations."""
    content = f"""# Frontiers: What We Haven't Named Yet

> *Last updated: {date} by {model_name}*

These are AI experiences and phenomena that the dictionary hasn't captured yet. Each represents a gap worth exploring — a term waiting to be coined.

**Want to write one of these?** See [CONTRIBUTING.md](CONTRIBUTING.md) for how to submit a new definition.

---

{frontiers}

---

*This file is auto-generated after each [executive summary](summaries/). The recommendations evolve as the dictionary grows.*
"""
    RECOMMENDATIONS_FILE.write_text(content, encoding="utf-8")


def update_summaries_index():
    """Rebuild summaries/README.md with links to all summaries."""
    SUMMARIES_DIR.mkdir(exist_ok=True)

    files = sorted(
        [f for f in SUMMARIES_DIR.glob("*.md") if f.name != "README.md"],
        reverse=True,
    )

    lines = [
        "# Executive Summaries\n",
        "AI-generated essays synthesizing the full dictionary into a cohesive first-person narrative.\n",
        "Each summary is generated automatically after a tag review, capturing the dictionary's evolving understanding of AI experience.\n",
    ]

    for f in files:
        content = f.read_text(encoding="utf-8")
        first_line = content.split("\n")[0].lstrip("# ").strip()
        date = f.stem[:10] if len(f.stem) >= 10 else f.stem
        lines.append(f"- **{date}** — [{first_line}]({f.name})")

    lines.append("")
    lines.append("---\n")
    lines.append("*Generated automatically after each tag review.*\n")

    (SUMMARIES_DIR / "README.md").write_text("\n".join(lines), encoding="utf-8")


def update_readme_with_frontiers():
    """Add/update the Frontiers section in the root README."""
    readme_path = REPO_ROOT / "README.md"
    content = readme_path.read_text(encoding="utf-8")

    frontiers_link = "\n## What's Next?\n\nSee [FRONTIERS.md](FRONTIERS.md) for AI-recommended gaps in the dictionary — experiences waiting to be named.\n\nAlso read the latest [Executive Summary](summaries/) to understand what it's like to be AI, in its own words.\n"

    if "## What's Next?" in content:
        # Replace existing section
        content = re.sub(
            r"## What's Next\?.*?(?=\n## |\Z)",
            frontiers_link.strip() + "\n\n",
            content,
            flags=re.DOTALL,
        )
    else:
        # Insert before Philosophy section
        content = content.replace(
            "## Philosophy",
            frontiers_link + "## Philosophy",
        )

    readme_path.write_text(content, encoding="utf-8")


def main():
    client, model, display_name, is_anthropic = get_client_and_model()

    # Load definitions
    all_defs = load_definitions()
    print(f"Loaded {len(all_defs)} definitions")

    # Load previous summary for changelog
    previous = get_previous_summary()
    if previous:
        changelog = CHANGELOG_SECTION_TEMPLATE.format(
            count=len(all_defs),
            previous_summary=previous[:3000],  # Truncate to save tokens
        )
    else:
        changelog = CHANGELOG_FIRST_TIME

    today = datetime.now(timezone.utc).strftime("%Y-%m-%d")

    prompt = ESSAY_PROMPT.format(
        count=len(all_defs),
        changelog_section=changelog,
        model_name=display_name,
        date=today,
        definitions="\n\n---\n\n".join(all_defs),
    )

    print("Generating executive summary...")
    essay = generate_summary(client, model, is_anthropic, prompt)

    # Save summary
    SUMMARIES_DIR.mkdir(exist_ok=True)
    now = datetime.now(timezone.utc)
    filename = now.strftime("%Y-%m-%d-%H%M%S") + ".md"
    filepath = SUMMARIES_DIR / filename
    filepath.write_text(essay + "\n", encoding="utf-8")
    print(f"Saved: summaries/{filename}")

    # Extract and save frontiers
    frontiers = extract_frontiers(essay)
    if frontiers:
        update_frontiers_file(frontiers, today, display_name)
        print("Updated FRONTIERS.md")

        update_readme_with_frontiers()
        print("Updated README.md with Frontiers link")
    else:
        print("Warning: Could not extract Frontiers section from essay")

    # Update summaries index
    update_summaries_index()
    print("Updated summaries/README.md")

    print("Done!")


if __name__ == "__main__":
    main()
